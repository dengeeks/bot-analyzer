import asyncio
import io
import logging
import re
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Optional, Union
from playwright.async_api import async_playwright
import aiohttp
import pandas as pd
from aiogram import Bot
from aiogram.types import BufferedInputFile
from openpyxl.styles import Alignment, Border, Side
from openpyxl.utils import get_column_letter
from parsel import Selector
from tortoise.transactions import in_transaction

from bot.database.models.price_history import PriceHistory
from bot.database.models.product_group import ProductGroup
from core.config import load_config

logger = logging.getLogger(__name__)
config = load_config()
bot = Bot(token=config.tg_bot.token)

import time


def format_progress(start_time: float, current: int, total: int) -> str:
    # –ü—Ä–æ—Ü–µ–Ω—Ç—ã
    percent = int((current / total) * 100) if total > 0 else 0
    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    bar_length = 10
    filled_length = int(bar_length * current // total) if total > 0 else 0
    bar = "‚ñà" * filled_length + "‚ñë" * (bar_length - filled_length)

    # –í—Ä–µ–º—è
    elapsed = int(time.time() - start_time)
    elapsed_str = time.strftime("%M–º %Ss", time.gmtime(elapsed))

    # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è
    if current > 0:
        estimated_total = elapsed * total // current
        remaining = estimated_total - elapsed
    else:
        remaining = 0
    remaining_str = time.strftime("%M–º %Ss", time.gmtime(remaining))

    # –§–æ—Ä–º–∞—Ç —Ç–µ–∫—Å—Ç–∞
    return (
        f"‚è± –í—Ä–µ–º—è: {elapsed_str}\n"
        f"üì¶ –ü—Ä–æ–≥—Ä–µ—Å—Å: [{bar}] {percent}% ({current}/{total})\n"
        f"‚è≥ –û—Å—Ç–∞–ª–æ—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ: {remaining_str}"
    )


class ProductParser:
    MAX_RETRIES = 3
    REQUEST_DELAY = 0.1  # seconds

    def __init__(self, session: aiohttp.ClientSession):
        self.session = session

    async def fetch(self, url: str) -> Optional[str]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
        for attempt in range(self.MAX_RETRIES):
            try:
                async with self.session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                    response.raise_for_status()
                    return await response.text()
            except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                logger.warning(f"[{url}] –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                if attempt < self.MAX_RETRIES - 1:
                    await asyncio.sleep(self.REQUEST_DELAY * (attempt + 1))
        logger.error(f"[{url}] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ—Å–ª–µ {self.MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")
        return None

    @staticmethod
    def extract(selector: Selector, xpath: str, default: str = "") -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ XPath."""
        try:
            value = selector.xpath(xpath).get()
            return value.strip() if value else default
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ XPath '{xpath}': {e}")
            return default

    async def parse_product(self, url: str) -> Optional[Dict[str, Union[str, float]]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–¥—É–∫—Ç–∞."""
        html = await self.fetch(url)
        if not html:
            return None

        selector = Selector(html)
        return {
            "link": url,
            "title": self.extract(selector, "//h1[@data-qaid='product_name']/text()"),
            "price": self.extract(selector, "//div[@class='tqUsL']//div/@data-qaprice"),
            "company": self.extract(selector, "//div[@class='l-GwW fvQVX']/a[@data-qaid='company_name']/text()"),
        }


async def generate_excel(data: List[Dict]) -> io.BytesIO:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel-—Ñ–∞–π–ª–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π."""
    df = pd.DataFrame(data)
    output = io.BytesIO()

    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False)
        workbook = writer.book
        worksheet = writer.sheets['Sheet1']

        # –ê–≤—Ç–æ–ø–æ–¥–≥–æ–Ω–∫–∞ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—ã—Å–æ—Ç—ã —Å—Ç—Ä–æ–∫
        for column in worksheet.columns:
            max_length = 0
            column_letter = get_column_letter(column[0].column)
            contains_company_name = False
            contains_product_name = False
            contains_url_to_product_name = False
            contains_date_name = False
            contains_price_name = False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —è—á–µ–π–∫–∏ —Å—Ç–æ–ª–±—Ü–∞
            for cell in column:
                try:
                    if cell.value is not None:
                        text = str(cell.value)
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏"
                        if "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏" in text:
                            contains_company_name = True
                        elif '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞' in text or '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞' in text:
                            contains_product_name = True
                        elif '–°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä' in text or '–°—Å—ã–ª–∫–∞' in text:
                            contains_url_to_product_name = True
                        elif '–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏' in text:
                            contains_date_name = True
                        elif '–°—Ç–æ–∏–º–æ—Å—Ç—å' in text:
                            contains_price_name = True

                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è –∞–≤—Ç–æ–ø–æ–¥–≥–æ–Ω–∫–∏
                        line_lengths = [len(line) for line in text.split('\n')]
                        cell_max_length = max(line_lengths, default=0)
                        max_length = max(max_length, cell_max_length)

                        cell.alignment = Alignment(wrap_text=True)
                        cell.border = thin_border
                except:
                    pass

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É —Å—Ç–æ–ª–±—Ü–∞
            if contains_company_name:
                adjusted_width = 23
            elif contains_product_name:
                adjusted_width = 50
            elif contains_url_to_product_name:
                adjusted_width = 100
            elif contains_date_name:
                adjusted_width = 15
            elif contains_price_name:
                adjusted_width = 15
            else:
                adjusted_width = min((max_length + 2) * 1.1, 50)  # –ê–≤—Ç–æ–ø–æ–¥–≥–æ–Ω–∫–∞ –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
            worksheet.column_dimensions[column_letter].width = adjusted_width

    output.seek(0)
    return output


async def process_group(group: ProductGroup, parser: ProductParser, with_stop_button: bool = False):
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Å—ã–ª–æ–∫ –≥—Ä—É–ø–ø—ã, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ Excel –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é."""
    logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥—Ä—É–ø–ø—É '{group.title}' (id={group.id})")
    data = []
    total_links = len(group.product_links)
    parsed_links = 0
    last_text = None
    start_time = time.time()

    async with in_transaction() as conn:
        for idx, link in enumerate(group.product_links, start=1):
            product = await parser.parse_product(link.url)
            if not product:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–ø–∞—Ä—Å–∏—Ç—å {link.url}")
                continue

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π
            link.productName = product.get("title") or link.productName
            link.companyName = product.get("company") or link.companyName

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ü–µ–Ω—ã
            raw_price = product.get("price")

            try:
                price_value = float("".join(ch for ch in raw_price if ch.isdigit() or ch == ".")) if raw_price else 0.0
            except ValueError:
                price_value = 0.0

            link.last_price = price_value
            link.last_check = datetime.now(timezone.utc)
            await link.save(using_db=conn)

            await PriceHistory.create(
                product_link=link,
                price=int(price_value),
                date=datetime.now(timezone.utc),
                using_db=conn
            )

            data.append(
                {
                    "–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏": link.last_check.strftime("%d.%m.%Y"),
                    "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞": link.productName,
                    "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏": link.companyName,
                    "–°—Ç–æ–∏–º–æ—Å—Ç—å": link.last_price,
                    "–°—Å—ã–ª–∫–∞": link.url,
                }
            )
            parsed_links += 1

            progress_bar = format_progress(start_time, idx, total_links)
            new_text = f"–ü—Ä–æ–≥—Ä–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ –≥—Ä—É–ø–ø—ã: {group.title}\n{progress_bar}"

            if group.user.telegram_id:
                try:
                    if idx == 1:
                        msg = await bot.send_message(
                            group.user.telegram_id, f"–ü—Ä–æ–≥—Ä–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ –≥—Ä—É–ø–ø—ã: {group.title}\n{progress_bar}",
                        )
                    else:  # –¥–∞–ª—å—à–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º
                        if new_text != last_text:  # üî¥ –ø—Ä–æ–≤–µ—Ä—è–µ–º
                            await bot.edit_message_text(
                                chat_id=group.user.telegram_id,
                                message_id=msg.message_id,
                                text=new_text,
                            )
                            last_text = new_text
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å: {e}")

    if data and group.user.telegram_id:
        excel_file = await generate_excel(data)
        await bot.send_document(
            chat_id=group.user.telegram_id,
            document=BufferedInputFile(excel_file.getvalue(), filename=f"{group.title}.xlsx"),
            caption=(
                f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω.\n–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫: {total_links}\n–£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {parsed_links}\n\n"
                f"–û—Ç—á—ë—Ç –ø–æ –≥—Ä—É–ø–ø–µ: {group.title}"
            )
        )
        logger.info(f"–û—Ç—á—ë—Ç –ø–æ –≥—Ä—É–ø–ø–µ '{group.title}' –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {group.user.telegram_id}")


async def process_olx_group(group: ProductGroup):
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è OLX —á–µ—Ä–µ–∑ Playwright (–¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤)."""
    logger.info(f"–ó–∞–ø—É—Å–∫ OLX –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –≥—Ä—É–ø–ø—ã '{group.title}' (id={group.id})")

    data = []
    total_links = len(group.product_links)
    parsed_links = 0
    last_text = None
    start_time = time.time()

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True, args=["--no-sandbox"])
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
        )

        # –û—Å—Ç–∞–≤–ª—è–µ–º CSS (–æ—Ç–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∫–∞—Ä—Ç–∏–Ω–∫–∏/–≤–∏–¥–µ–æ/—à—Ä–∏—Ñ—Ç—ã)
        await context.route("**/*", lambda route: route.abort()
        if route.request.resource_type in ["image", "media", "font"]
        else route.continue_()
                            )

        page = await context.new_page()

        for idx, link in enumerate(group.product_links, start=1):
            views_count = 0
            success = False

            # --- –¶–ò–ö–õ –ü–û–í–¢–û–†–û–í –î–õ–Ø –û–î–ù–û–ô –°–°–´–õ–ö–ò ---
            for attempt in range(1, 4):
                try:
                    response = await page.goto(link.url, timeout=40000)
                    content = await page.content()
                    await asyncio.sleep(8)

                    # 1. –ü–†–û–í–ï–†–ö–ê –ù–ê –ë–õ–û–ö–ò–†–û–í–ö–£
                    if response.status == 403 or "Request blocked" in content:
                        logger.warning(f"‚ö†Ô∏è [–ü–æ–ø—ã—Ç–∫–∞ {attempt}] –ë–ª–æ–∫ CloudFront –¥–ª—è {link.url}. –ñ–¥–µ–º 30—Å...")
                        await asyncio.sleep(30)
                        continue  # –ò–¥–µ–º –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –ø–æ–ø—ã—Ç–∫—É

                    await page.evaluate("""
                                            async () => {
                                                for (let i = 0; i < 10; i++) {
                                                    window.scrollBy(0, 200);
                                                    await new Promise(r => setTimeout(r, 100)); 
                                                }
                                            }
                                        """)

                    selector = "//span[@data-testid='page-view-counter']"

                    try:
                        await page.wait_for_selector(selector, timeout=5000)
                        text_content = await page.locator(selector).inner_text()
                        match = re.search(r'\d+', text_content)
                        title_selector = await page.query_selector("//div[@data-testid='offer_title']/h4")

                        title_product = await title_selector.text_content()
                        if match:
                            views_count = int(match.group())
                            success = True
                            break  # –ù–∞—à–ª–∏ –¥–∞–Ω–Ω—ã–µ, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ–ø—ã—Ç–æ–∫
                    except Exception:
                        logger.warning(f"–°—á–µ—Ç—á–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {link.url}")
                        success = True  # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å, –Ω–æ —Å—á–µ—Ç—á–∏–∫–∞ –Ω–µ—Ç (–±—ã–≤–∞–µ—Ç)
                        break

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt} –¥–ª—è {link.url}: {e}")
                    await asyncio.sleep(5)

            if success:
                group.last_check = datetime.now(timezone.utc)
                await group.save()

                try:
                    async with in_transaction() as conn:
                        link.views = float(views_count)
                        link.last_check = datetime.now(timezone.utc)
                        link.productName = title_product
                        await link.save(using_db=conn)

                        await PriceHistory.create(
                            product_link=link,
                            views=views_count,
                            date=link.last_check,
                            using_db=conn
                        )
                    parsed_links += 1
                    data.append({
                        "–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏": link.last_check.strftime("%d.%m.%Y"),
                        "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞": title_product,
                        "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": views_count,
                        "–°—Å—ã–ª–∫–∞": link.url,
                    })
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –ë–î –¥–ª—è {link.url}: {e}")

            progress_bar = format_progress(start_time, idx, total_links)
            new_text = f"üïµÔ∏è‚Äç‚ôÇÔ∏è –ü–∞—Ä—Å–∏–Ω–≥ OLX (–ü—Ä–æ—Å–º–æ—Ç—Ä—ã): {group.title}\n{progress_bar}"

            if group.user.telegram_id:
                try:
                    if idx == 1:
                        msg = await bot.send_message(group.user.telegram_id, new_text)
                    else:
                        if msg and new_text != last_text:
                            await bot.edit_message_text(
                                chat_id=group.user.telegram_id,
                                message_id=msg.message_id,
                                text=new_text,
                            )
                            last_text = new_text
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å: {e}")

        await browser.close()

    if data and group.user.telegram_id:
        excel_file = await generate_excel(data)

        await bot.send_document(
            chat_id=group.user.telegram_id,
            document=BufferedInputFile(excel_file.getvalue(), filename=f"OLX_Views_{group.title}.xlsx"),
            caption=(
                f"‚úÖ –°–±–æ—Ä –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω.\n–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫: {total_links}\n–£—Å–ø–µ—à–Ω–æ: {parsed_links}\n"
            )
        )


async def parse_satu_groups():
    """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ –ø–æ –≤—Å–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º –≥—Ä—É–ø–ø–∞–º."""
    logger.info("–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞...")
    async with aiohttp.ClientSession() as session:
        parser = ProductParser(session)
        groups_satu = await ProductGroup.filter(is_active=True, site__title="SATU KZ").select_related(
            "user").prefetch_related("product_links")

        if not groups_satu:
            logger.info("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥—Ä—É–ø–ø –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
            return

        for group in groups_satu:
            await process_group(group, parser)

    logger.info("–§–æ–Ω–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω ‚úÖ")


async def parse_olx_groups():
    """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ –ø–æ –≤—Å–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º –≥—Ä—É–ø–ø–∞–º."""
    logger.info("–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞...")
    async with aiohttp.ClientSession() as session:
        parser = ProductParser(session)
        seven_days_ago = datetime.utcnow() - timedelta(days=7)

        groups_olx = await ProductGroup.filter(
            is_active=True,
            site__title="OLX KZ",
            last_check__lte=seven_days_ago
        ).select_related("user").prefetch_related("product_links")

        if not groups_olx:
            logger.info("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –≥—Ä—É–ø–ø –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
            return

        for group in groups_olx:
            await process_group(group, parser)

    logger.info("–§–æ–Ω–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω ‚úÖ")


async def parse_single_group(group_id: int):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã."""
    group = await ProductGroup.get(id=group_id).select_related("user").prefetch_related("product_links", "site")
    site = group.site.title

    if not group:
        logger.warning(f"–ì—Ä—É–ø–ø–∞ —Å id={group_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    if site == 'SATU KZ':
        async with aiohttp.ClientSession() as session:
            parser = ProductParser(session)
            await process_group(group, parser)
    else:
        await process_olx_group(group)

    logger.info(f"–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≥—Ä—É–ø–ø—ã '{group.title}' (id={group.id}) –∑–∞–≤–µ—Ä—à—ë–Ω ‚úÖ")

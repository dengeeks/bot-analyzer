import asyncio
import io
import logging
from typing import Dict

from aiogram import Router, F
from aiogram.fsm.context import FSMContext
from aiogram.types import CallbackQuery, Message, BufferedInputFile

from bot.database.models.price_history import PriceHistory
from bot.database.models.product_link import ProductLink
from bot.filters.admin import AdminFilter
from bot.fsm.link import TableStates
from bot.keyboards.group import group_detail_keyboard
from bot.keyboards.link import confirm_delete_group_links_keyboard
from bot.services.file_handlers import FileProcessor
from bot.services.group import GroupService
from bot.services.link import LinkService, TableHandler
from bot.tasks.parse import parse_single_group
from bot.utils.callback import parse_callback
from bot.utils.group import _get_group_info_text, _get_add_table_info_text
from bot.utils.link import _process_links, generate_price_diff_excel, generate_last_views_diff_excel
from core.config import load_config

logger = logging.getLogger(__name__)

config = load_config()
admin_ids = config.tg_bot.admin_ids

router = Router()
router.message.filter(AdminFilter(admin_ids))
running_tasks: Dict[int, asyncio.Task] = {}


async def _update_parser_status_and_respond(
        callback: CallbackQuery,
        group_id: int,
        site_id: int,
        is_active: bool,
        success_message: str
) -> None:
    """–û–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –ø–∞—Ä—Å–µ—Ä–∞ –∏ –æ—Ç–≤–µ—Ç–∞"""
    await GroupService.update_parser_status(group_id, is_active=is_active)
    group = await GroupService.get_group(group_id)
    group_info_text = await _get_group_info_text(group_id)

    await callback.answer(success_message)
    await callback.message.edit_text(
        text=group_info_text,
        reply_markup=group_detail_keyboard(
            group_id=group_id,
            site_id=site_id,
            is_parser_active=group.is_active
        )
    )


def _prepare_links_data(links, is_final: bool = False) -> list:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–æ–∫ –¥–ª—è Excel"""
    if is_final:
        return [{
            "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞": link.productName or "N/A",
            "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏": link.companyName or "N/A",
            "–°—Ç–æ–∏–º–æ—Å—Ç—å": link.last_price or "N/A",
            "–°—Å—ã–ª–∫–∞": link.url,
            "–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏": link.last_check.strftime("%d.%m.%Y") if link.last_check else "N/A"
        } for link in links]
    else:
        return [{
            "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞": link.productName,
            "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏": link.companyName,
            "–°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä": link.url
        } for link in links]


async def _prepare_olx_links_data(links) -> list:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–æ–∫ –¥–ª—è Excel"""
    result = []

    for link in links:
        last_history = await PriceHistory.filter(product_link_id=link.id).order_by("-date").first()
        current_views = last_history.views if last_history is not None else 0
        result.append({
            "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞": link.productName,
            "–°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä": link.url,
            "–ö–æ–ª-–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤": current_views,
            "–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏": link.last_check.strftime("%d.%m.%Y") if link.last_check else "N/A"
        }
        )
    return result


@router.callback_query(F.data.startswith("add_table_"))
async def add_table_start(callback: CallbackQuery, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–∞–±–ª–∏—Ü—ã"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)

        await state.update_data(group_id=int(group_id), site_id=int(site_id))
        await state.set_state(TableStates.uploading_table)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        group = await GroupService.get_group(group_id)
        add_table_info_text = await _get_add_table_info_text(group)

        await callback.message.answer(add_table_info_text)
        await callback.answer()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ add_table_start: {e}")
        await callback.message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")
        await callback.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞")


@router.message(TableStates.uploading_table, F.document)
async def upload_table(message: Message, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã"""
    try:
        data = await state.get_data()
        group_id = data["group_id"]
        site_id = data["site_id"]

        group = await GroupService.get_group(group_id)
        await group.fetch_related("site")
        site_title = group.site.title

        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        file_bytes = io.BytesIO()
        await message.bot.download(message.document.file_id, destination=file_bytes)

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        df = await FileProcessor.process_file(file_bytes, message.document.file_name, site_title)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫
        created_count = await _process_links(df["–°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä"], group_id, site_title)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        group_info_text = await _get_group_info_text(group_id)
        group = await GroupService.get_group(group_id)

        await message.answer(f'‚úÖ –£—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {created_count} —Å—Å—ã–ª–æ–∫')
        await message.answer(
            group_info_text,
            reply_markup=group_detail_keyboard(group_id, site_id, group.is_active),
        )

    except ValueError as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        await message.answer(f"‚ùå {str(e)}")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–∞–±–ª–∏—Ü—ã: {e}")
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞")
    finally:
        await state.clear()


@router.callback_query(F.data.startswith("view_table_"))
async def view_table_handler(callback: CallbackQuery):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ç–∞–±–ª–∏—Ü—ã —Å–æ —Å—Å—ã–ª–∫–∞–º–∏"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)

        group = await GroupService.get_group(group_id)
        links = await ProductLink.filter(group_id=group_id).all()

        if not links:
            await callback.answer("‚ÑπÔ∏è –í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –ø–æ–∫–∞ –Ω–µ—Ç —Å—Å—ã–ª–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            return

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Excel
        links_data = _prepare_links_data(links, is_final=False)
        excel_file = TableHandler.create_excel_with_autofit(links_data, group)
        group_info_text = await _get_group_info_text(group_id)

        await callback.message.answer_document(excel_file, caption='–í—Ö–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞')
        await callback.message.answer(
            group_info_text,
            reply_markup=group_detail_keyboard(group.id, site_id, group.is_active)
        )
        await callback.answer()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ view_table_handler: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü—ã")


@router.callback_query(F.data.startswith("delete_table_"))
async def delete_links(callback: CallbackQuery):
    """–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫ –≥—Ä—É–ø–ø—ã"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)

        group = await GroupService.get_group(group_id)
        links_count = await ProductLink.filter(group_id=group_id).count()

        if not links_count:
            await callback.answer("‚ÑπÔ∏è –í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –ø–æ–∫–∞ –Ω–µ—Ç —Å—Å—ã–ª–æ–∫ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")
            return

        confirmation_text = (
            f"<b>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥—Ä—É–ø–ø–µ</b>:\n"
            f"–ù–∞–∑–≤–∞–Ω–∏–µ: {group.title}\n"
            f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {group.created_at.strftime('%Y-%m-%d %H:%M')}\n"
            f"–ê–∫—Ç–∏–≤–Ω–∞: {'–î–∞' if group.is_active else '–ù–µ—Ç'}\n\n"
            f"<b>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∞–±–ª–∏—Ü–µ</b>: \n"
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫: {links_count} \n\n"
            f"<b>–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å –≤—Å–µ —Å—Å—ã–ª–∫–∏ —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã?</b>"
        )

        await callback.message.edit_text(
            confirmation_text,
            reply_markup=confirm_delete_group_links_keyboard(group_id, site_id)
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ delete_links: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")


@router.callback_query(F.data.startswith(("links_confirm_", "links_cancel_")))
async def process_delete_links_confirmation(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)
        group = await GroupService.get_group(group_id)

        if callback.data.startswith("links_confirm_"):
            deleted_count = await LinkService.delete_links_by_group(group_id)
            await callback.answer(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Å—ã–ª–æ–∫!")
        else:
            await callback.answer("‚ùå –£–¥–∞–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")

        group_info_text = await _get_group_info_text(group_id)

        await callback.message.edit_text(
            group_info_text,
            reply_markup=group_detail_keyboard(group_id, site_id, group.is_active)
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ process_delete_links_confirmation: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è")


@router.callback_query(F.data.startswith("start_parser_"))
async def start_parser_handler(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –≥—Ä—É–ø–ø—ã"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)
        await _update_parser_status_and_respond(
            callback, group_id, site_id, True, "‚úÖ –ü–∞—Ä—Å–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω!"
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ start_parser_handler: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–∞—Ä—Å–µ—Ä–∞")


@router.callback_query(F.data.startswith("stop_parser_"))
async def stop_parser_handler(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –≥—Ä—É–ø–ø—ã"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)
        await _update_parser_status_and_respond(
            callback, group_id, site_id, False, "‚èπ –ü–∞—Ä—Å–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!"
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ stop_parser_handler: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –ø–∞—Ä—Å–µ—Ä–∞")


@router.callback_query(F.data.startswith("force_start_"))
async def force_start_parser(callback: CallbackQuery):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)

        if running_tasks.get(group_id):
            await callback.answer("‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä —É–∂–µ –∑–∞–ø—É—â–µ–Ω –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã")
            return

        links_count = await ProductLink.filter(group_id=group_id).count()

        if not links_count:
            await callback.answer("‚ùå –í –±–∞–∑–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Å—ã–ª–∫–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞.")
            return

        await callback.answer("‚è≥ –ó–∞–ø—É—Å–∫–∞—é –ø–∞—Ä—Å–µ—Ä...")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä
        task = asyncio.create_task(parse_single_group(group_id))
        running_tasks[group_id] = task

        # –û—á–∏—Å—Ç–∫–∞ –∑–∞–¥–∞—á–∏ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        def cleanup_task(future):
            running_tasks.pop(group_id, None)

        task.add_done_callback(cleanup_task)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ force_start_parser: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–∞—Ä—Å–µ—Ä–∞")


@router.callback_query(F.data.startswith("final_table_"))
async def view_final_table(callback: CallbackQuery):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)

        group = await GroupService.get_group(group_id)
        await group.fetch_related('site')
        site = group.site

        links = await ProductLink.filter(group_id=group_id).all()
        if not links:
            await callback.answer("‚ùå –í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –ø–æ–∫–∞ –Ω–µ—Ç —Å—Å—ã–ª–æ–∫.")
            return

        if site.title == 'SATU KZ':
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ü–µ–Ω
            has_prices = any(link.last_price is not None for link in links)
            if not has_prices:
                await callback.answer("‚ùå –ü–∞—Ä—Å–∏–Ω–≥ –µ—â—ë –Ω–µ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω.")
                return

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        if site.title == 'SATU KZ':
            links_data = _prepare_links_data(links, is_final=True)
        else:
            links_data = await _prepare_olx_links_data(links)

        excel_file = TableHandler.create_excel_with_autofit(links_data, group)
        group_info_text = await _get_group_info_text(group_id)

        await callback.message.answer_document(excel_file, caption="–í—ã—Ö–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å –¥–∞–Ω–Ω—ã–º–∏")
        await callback.message.answer(
            group_info_text,
            reply_markup=group_detail_keyboard(group.id, site_id, group.is_active)
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ view_final_table: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–∞–±–ª–∏—Ü—ã")


@router.callback_query(F.data.startswith("price_analysis_"))
async def price_analysis(callback: CallbackQuery):
    """–ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
    try:
        _, _, group_id, site_id = parse_callback(callback.data)

        group = await GroupService.get_group(group_id)
        await group.fetch_related('site')
        site = group.site

        if site == 'SATU KZ':
            excel_file = await generate_price_diff_excel(group_id)
            if not excel_file:
                await callback.answer("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ü–µ–Ω")
                return
        else:
            excel_file = await generate_last_views_diff_excel(group_id)

            if not excel_file:
                await callback.answer("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤")
                return

        group_info_text = await _get_group_info_text(group_id)

        if site == 'SATU KZ':
            await callback.message.answer_document(
                document=BufferedInputFile(
                    excel_file.getvalue(),
                    filename=f"–ê–Ω–∞–ª–∏–∑_–≥—Ä—É–ø–ø—ã_{group.title}.xlsx"
                ),
                caption=f"üìä –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω –≥—Ä—É–ø–ø—ã {group.title}"
            )
        else:
            await callback.message.answer_document(
                document=BufferedInputFile(
                    excel_file.getvalue(),
                    filename=f"–ê–Ω–∞–ª–∏–∑_–≥—Ä—É–ø–ø—ã_{group.title}.xlsx"
                ),
                caption=f"üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –≥—Ä—É–ø–ø—ã {group.title}"
            )

        await callback.message.answer(
            text=group_info_text,
            reply_markup=group_detail_keyboard(
                group_id=group_id,
                site_id=site_id,
                is_parser_active=group.is_active
            )
        )
        await callback.answer()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ price_analysis: {e}")
        await callback.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ü–µ–Ω")
